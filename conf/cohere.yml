# Copyright 2023 Aineko Authors
# SPDX-License-Identifier: Apache-2.0
pipeline:
  name: template-generator

  default_node_settings:
    num_cpus: 0.5

  nodes:
    # Prompt generation
    GitHubDocFetcher:
      class: aineko_dream.nodes.GitHubDocFetcher
      inputs:
        - github_events
      outputs:
        - documents
      node_params:
        organization: Convex-Labs
        repo: aineko
        branch: documentation
        file_path: "/docs/public/gitbook/aineko/04_developer_guide/building-a-pipeline.md"
    PromptModel:
      class: aineko_dream.nodes.PromptModel
      inputs:
        - user_prompt
        - documents
      outputs:
        - llm_prompt
      node_params:
        routing_preferences:
          company_slack: GPT3Client
          public_slack: GPT3Client

    # LLM Client
    CohereClient:
      class: aineko_dream.nodes.Cohere
      inputs:
        - llm_prompt
      outputs:
        - llm_response
      node_params:
        model: "command"
        max_tokens: 4000
        temperature: 0.1
        role: engineer

    # Response evaluation
    ResponseFormatter:
      class: aineko_dream.nodes.ResponseFormatter
      inputs:
        - llm_response
      outputs:
        - formatted_llm_response
    FrameworkEvaluation:
      class: aineko_dream.nodes.FrameworkEvaluation
      inputs:
        - formatted_llm_response
      outputs:
        - evaluation_result
    SecurityEvaluation:
      class: aineko_dream.nodes.SecurityEvaluation
      inputs:
        - formatted_llm_response
      outputs:
        - evaluation_result
    EvaluationModel:
      class: aineko_dream.nodes.EvaluationModel
      inputs:
        - llm_prompt
        - formatted_llm_response
        - evaluation_result
      outputs:
        - final_response
        - llm_prompt

    # API
    ResponseCache:
      class: aineko_dream.nodes.ResponseCache
      inputs:
        - final_response
      outputs:
        - response_cache
      node_params:
        cleanup_interval: 600
    APIServer:
      class: aineko_dream.nodes.APIServer
      inputs:
        - response_cache
      outputs:
        - user_prompt
        - github_events
      node_params:
        app: aineko_dream.api.main:app
        port: 8000

  datasets:
    github_events:
      type: kafka_stream
    documents:
      type: kafka_stream
    user_prompt:
      type: kafka_stream
    llm_prompt:
      type: kafka_stream
    llm_response:
      type: kafka_stream
    formatted_llm_response:
      type: kafka_stream
    evaluation_result:
      type: kafka_stream
    final_response:
      type: kafka_stream
    response_cache:
      type: kafka_stream
